{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pron fool people time people time pron fool people time abraham lincoln\n",
      "\n",
      "pron can fool some of the people all of the time and all of the people some of the time but pron can not fool all of the people all of the time abraham lincoln\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "STOPLIST = ENGLISH_STOP_WORDS\n",
    "STOPLIST = set(list(STOPLIST) + [\"foo\"])\n",
    "\n",
    "def lemmatize_document(doc, stop_words=None):\n",
    "    \"\"\"\n",
    "    takes a list of strings where each string is a document\n",
    "    returns a processed list of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if not stop_words:\n",
    "        stop_words = set([])\n",
    "  \n",
    "    ## ensure working with string\n",
    "    doc = str(doc)\n",
    "\n",
    "    # First remove punctuation form string\n",
    "    if sys.version_info.major == 3:\n",
    "        PUNCT_DICT = {ord(punc): None for punc in punctuation}\n",
    "        doc = doc.translate(PUNCT_DICT)\n",
    "\n",
    "    # remove unicode\n",
    "    clean_doc = \"\".join([char for char in doc if char in printable])\n",
    "            \n",
    "    # Run the doc through spaCy\n",
    "    doc = nlp(clean_doc)\n",
    "\n",
    "    # Lemmatize and lower text\n",
    "    tokens = [re.sub(\"\\W+\",\"\",token.lemma_.lower()) for token in doc ]\n",
    "    tokens = [t for t in tokens if len(t) > 1]\n",
    "    \n",
    "    return ' '.join(w for w in tokens if w not in stop_words)   \n",
    "    \n",
    "## example usage\n",
    "corpus = ['\"You can fool some of the people all of the time, and all of the people some of the time, but you can not fool all of the people all of the time\". -- Abraham Lincoln']\n",
    "processed = [lemmatize_document(doc, STOPLIST) for doc in corpus]\n",
    "print(processed[0])\n",
    "processed = [lemmatize_document(doc, None) for doc in corpus]\n",
    "print(\"\\n\"+processed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://player.vimeo.com/video/87110435\" width=\"640\" height=\"360\"  frameborder=\"0\" allowfullscreen></iframe>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
